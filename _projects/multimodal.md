---
title: Multimodal Learning

description: |
  Design, understand, and evaluate multimodality in multilingual models

people:
  - desmond
  - emanuele
  - rita
  - wenyan
  - jonas

layout: project
last-updated: 2025-06-24
---

This line of research is focused on the representation and processing multimodal data. We create datasets and benchmarks, such as Multi30K, MaRVL, IGLUE, and FoodieQA with an increasing focus on data that is representative and created by the speakers of diverse languages. From a modelling perspective, we have created the mUNITER, xUNITER, TD-MML, and PAELLA models.

<div id="publications" style="font-size: 0.9rem;">
    <h4>Related Publications</h4>
    {% include multimodal.html %}
</div>
